#   LangChain

##  ▪️ Definition
LangChain is a *FrameWork* built round [LMs(**L**arge **L**guage **M**odels)](https://www.pinecone.io/learn/openai-gen-qa/) can be used for chatbots, Generative Question-Ansering, summarization ans more.

**Core Idea**: *"Chain "* different components together to create more advanced use cases around LLMS.
**Components**: 
  + **Prompt templates**: Like "chatbot" style templates, ELI5 question-answering, etc. Templates for different types of Prompts (Simple text, Dialog Prompt, Code an Instruction Prompt, all are in string form)
  + **LLMs**: Large Language models like GPT-3, BLOOM, etc
  + **Agents**: use LLMs to decide wht actions should be taken. Tools like web search or calculators are all avilable. They are all packed in a logical loop of operations.
  + **Memory**: Short-/Long-term memory
## ▪️ Start
### Creating a simple templates in langchain
'''

'''
where 
+ **temperature** parameter is to cntrol the randomness of the output generated by the OpenAI language model. It will influence the divercity of the model's responses.
  * High Temperature: encourages the model to produce more varied and unpredictable responses. This can lead to more creative outputs but may influence more errors or nonsensitive answers
  * Low Temperature: makes model more conservative and focused. It generates responses that are more deterministic and likely to be contextually appropriate. However, this can also result in more repetitive or safe responses.
+ 
