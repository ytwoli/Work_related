#   LangChain

##  ▪️ Definition
LangChain is a *FrameWork* built round [LMs(**L**arge **L**guage **M**odels)](https://www.pinecone.io/learn/openai-gen-qa/) can be used for chatbots, Generative Question-Ansering, summarization ans more.

**Core Idea**: *"Chain "* different components together to create more advanced use cases around LLMS.
**Components**: 
  + **Prompt templates**: Like "chatbot" style templates, ELI5 question-answering, etc. Templates for different types of Prompts (Simple text, Dialog Prompt, Code an Instruction Prompt, all are in string form)
  + **LLMs**: Large Language models like GPT-3, BLOOM, etc
  + **Agents**: use LLMs to decide wht actions should be taken. Tools like web search or calculators are all avilable. They are all packed in a logical loop of operations.
  + **Memory**: Short-/Long-term memory
## ▪️ [Start](/Get_Started/Introduction.ipynb)
### Creating a simple templates in langchain
For the basic setting:
<pre>
import os
from langchain import PromptTemplate
from langchain.llms import OpenAI
os.environ['OPENAI_API_KEY'] = "sk-.."
llm = OpenAI(temperature = 0.9)
</pre>

where 
+ **temperature** parameter is to cntrol the randomness of the output generated by the OpenAI language model. It will influence the divercity of the model's responses.
  * High Temperature: encourages the model to produce more varied and unpredictable responses. This can lead to more creative outputs but may influence more errors or nonsensitive answers
  * Low Temperature: makes model more conservative and focused. It generates responses that are more deterministic and likely to be contextually appropriate. However, this can also result in more repetitive or safe responses.

### Prompt Templates: Manage prompts for LLMs

## ▪️ Building Custom Tools for LLM Agents

**Agents** are one of the most powerful and fascination approaches to using LLMs. Using Agents allows us to give LLMs access to tools. 
### Building Tools
Tools are objects that consume some input and return output, both in form of *string*. For LangChain requires to recognize an object as a valid tool, we need two attributes: *name* and *description* parameters.
  + *description*:  a natural language description of the tool. Based on that,LLM can decide whether it needs to be use it. **COULD BE**: what they do, when to use and when not to use them 

**There are mainly four types of Agents:**
+ ***zero-shot-react-description***: This agent uses the ReAct framework to determine which tool to use based solely on the tool’s description. Any number of tools can be provided. This agent requires that a description is provided for each tool.
+ ***react-docstore***: This agent uses the ReAct framework to interact with a docstore. Two tools must be provided(they must be named exactly as so): 
    * a *Search* tool: search for a document
    * a *Lookup* tool: lookup a term in the most recently found document. 
+ ***self-ask-with-search***: This agent utilizes a single tool that should be named *Intermediate* Answer. This tool should be able to lookup factual answers to questions. This agent is equivalent to the original self ask with search paper, where a Google search API was provided as the tool.
+ ***conversational-react-description***: This agent is designed to be used in conversational settings. The prompt is designed to make the agent helpful and conversational. It uses the ReAct framework to decide which tool to use, and uses memory to remember the previous conversation interactions.
To buildcustom tools, we need first to initilize the **LLM** and **conversational memory** (for conversational agent). After that it also requires a list of tools, which are to be used. When all initial settings are done, we then need to create  agent using *langchain.agents.initilize_agent()*. With Parameters:
+ agent = *agent_type*
+ tools = *tool set we prepared*
+ llm = *llm*
+ verbose = True(?)
+ memory = *the conversational memory we created*

❗Take a look at the optput of the **AgentExecutor Chain**, it jumped straight to the **Final Answer** action, which means the agent decided *not* to use the tool. So we need more information to let it use the tools instead of 'overconfidence'. That's why we need to create a new prompt and replace the old one (if there has a method to add instead of create a new one?).  
